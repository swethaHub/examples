# topic config
io.confluent.developer.config.topic.name=test
io.confluent.developer.config.topic.replicas=3
io.confluent.developer.config.topic.partitions=6

# common configs 
spring.kafka.properties.ssl.endpoint.identification.algorithm=https
spring.kafka.properties.sasl.mechanism=PLAIN
spring.kafka.properties.request.timeout.ms=20000
spring.kafka.properties.bootstrap.servers=bootstrap-server.confluent.cloud:9092
spring.kafka.properties.retry.backoff.ms=500
spring.kafka.properties.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="<CLUSTER_API_KEY>" password="<CLUSTER_API_SECRET>";
spring.kafka.properties.security.protocol=SASL_SSL

# Cloud SR Config
spring.kafka.properties.basic.auth.credentials.source=USER_INFO
spring.kafka.properties.schema.registry.basic.auth.user.info=<SR_API_KEY>:<SR_API_SECRET>
spring.kafka.properties.schema.registry.url=https://sr.confluent.cloud:8080

# producer configuration
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=io.confluent.kafka.serializers.KafkaAvroSerializer

# consumer configuration 
spring.kafka.consumer.group-id=java-springboot
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=io.confluent.kafka.serializers.KafkaAvroDeserializerspring.kafka.consumer.value-deserializer=io.confluent.kafka.serializers.KafkaAvroDeserializer
spring.kafka.consumer.value-deserializer=io.confluent.kafka.serializers.KafkaAvroDeserializer

# kafka streams properties
spring.kafka.streams.application-id=count-aggregator
spring.kafka.streams.properties.default.key.serde=org.apache.kafka.common.serialization.Serdes$StringSerde
spring.kafka.streams.properties.default.value.serde=io.confluent.kafka.streams.serdes.avro.SpecificAvroSerde
spring.kafka.streams.properties.commit.interval.ms=0
spring.kafka.streams.properties.replication.factor=3